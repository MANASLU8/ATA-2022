Данный проект является результатом выполнения практических заданий курса ИТМО по автоматической обработке текстов (2022).

## Структура проекта

* `assets` - вспомогательные и конфигурационные файлы, не являющиеся исходным кодом.
    * `raw-dataset` - директория с исходными датасетами (добавлена в .gitignore).
    * `test` - генерируемая модулем токенизации директория.
    * `train` - генерируемая модулем токенизации директория c .
* `source` - исходный код.
    * `tokenizer` - модуль, реализующий функциональность токенизации.
    * `tests` - модульные тесты.
      * `test_tokenizer` - тесты для демонстации разработанной функциональности.
* `README.md` - описание.

## Подготовка окружения
Для корректной работы в директории `../assets/raw-dataset` должны располагаться два исходных датасета `train.csv` и `test.csv`.

## Запуск проекта

На данный момент реализован только токенизатор. Для его запуска следует выполнить следующую команду из директории source проекта
```
python __main__.py
```
Результатом выполнения является набор набор аннотаций в формате tsv в соответствии со следующей структурой:
```
<sentence_2_token_N>    <sentence_2_stem_N> <sentence_2_lemma_N>
```
Для выполнения лабораторных работ был выбран датасет https://huggingface.co/datasets/ag_news
В директории /assets/annotated-corpus сформированы каталоги train и test, в которых будет размещаться набор файлов с расширением tsv, содержащие аннотации документов, составляющих исходный датасет. 
Каждому документу исходного датасета соответствует отдельный файл, в качестве названия файла используется идентификатор документа. Документы группируются по директориям в соответствии с их разбиением на классы, название класса используется в качестве названия соответствующей директории.

Пример содержимого сгенерированных файлов
```
Companies	compani	Companies
surrenders	surrend	surrender
High-Capacity	high-capac	High-Capacity
ESPN	espn	ESPN
associate	associ	associate
"Music Manifesto"
,
```
Токены, не являющиеся словами, такие как аббревиатуры, знаки пунктуации, числа, названия в кавычках не участвуют в дальнейшей нормализации и не передаются для стемминга и лемматизации.


Для лемматизации использовался WordNetLemmatizer. Как можно заметить, он успешно привёл слово 'surrenders' к 'surrender', но 'Companies' осталось неизменным. 
Для того, чтобы учесть такие ситуации, следует различать слова в начале предложения от именованных сущностей и приводить слова в начале предложения к строчным буквам. Однако корректное распознавание именованных сущностей и их дифференцирование от слов в начале предложения возможно лишь при учёте семантики и недостижимо при использовании токенизатора только на основе регулярных выражений.

## Запуск тестов

Для системы разработан набор модульных тестов, позволяющих оценить корректность генерируемых результатов. Для запуска тестов используется следующая команда, которую необходимо выполнять из коревой директории проекта:

```sh
PYTHONPATH=source python -m unittest
```

Система отображает стандартный отчет о результатах выполненя тестов:

```sh
...
----------------------------------------------------------------------
Ran 3 tests in 0.002s

OK

OK
```
